{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a17b6c-5aaa-4605-8e22-2c2d268caa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67edc159-e46c-4208-8344-5ed300429974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7375afa-d8b3-4e2b-a7e7-947963f9e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576123d-eb9d-472d-b276-d454d509918a",
   "metadata": {},
   "source": [
    "# Summary of Lab:\n",
    "# 1. Input Tutoring Session\n",
    "\n",
    "# 2. Text Preprocessing with Torch with TorchText\n",
    "# The text is tokeniszed\n",
    "# Pretrained Glove word embeddings loading\n",
    "\n",
    "# 3. Using GPT - 2 for text Generation\n",
    "# A prompt is created that includes the tutoring session and a request\n",
    "# The model generates a response based on the prompt using beam search\n",
    "# The result is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e0ed0a-1bee-4e79-8463-6d2eb15536ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (from torchtext) (4.67.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from torchtext) (2.32.5)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (from torchtext) (2.9.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchtext) (2.3.5)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.13/site-packages (from torchtext) (1.17.0)\n",
      "Collecting sentencepiece (from torchtext)\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torchtext) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torchtext) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torchtext) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->torchtext) (2026.1.4)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch->torchtext) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch->torchtext) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch->torchtext) (3.0.2)\n",
      "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m423.3 kB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, torchtext\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchtext]\n",
      "\u001b[1A\u001b[2KSuccessfully installed sentencepiece-0.2.1 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6927e4de-c590-44a6-a7cc-736fcc831b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2026.1.4)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Installing collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.2.0 huggingface-hub-0.36.0 safetensors-0.7.0 tokenizers-0.22.2 transformers-4.57.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3bf5b15-7fbe-4d79-bfb8-66535bc89987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2f7f14e-6660-45b4-bb4d-6902261cdedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [05:39, 2.54MB/s]                                \n",
      "100%|█████████▉| 399999/400000 [00:05<00:00, 77387.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session embedding vector shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# TorchText Preprocessing\n",
    "\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "# Define input text\n",
    "session_text = \"This is a sample sentence for embedding.\"\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "tokens = tokenizer(session_text)\n",
    "\n",
    "# Load pretrained GloVe embeddings (100-dim)\n",
    "glove = GloVe(name=\"6B\", dim=100)\n",
    "\n",
    "# Filter tokens that exist in GloVe vocab\n",
    "token_vectors = [glove[token] for token in tokens if token in glove.stoi]\n",
    "\n",
    "# Mean pooling\n",
    "if token_vectors:\n",
    "    session_embedding = torch.stack(token_vectors).mean(dim=0)\n",
    "else:\n",
    "    session_embedding = torch.zeros(100)\n",
    "\n",
    "print(f\"Session embedding vector shape: {session_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd03601-55c8-4e25-be7e-c6bbedd1de47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389f1f2b50304aa8bd13c584d79a8995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3985d336f8304917981983693fde2704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d6b550d7cd42a8a3ed75556fa9f047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ca9b79d4c946c3a72129add88a6c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3e8fc1e478409faea2435924ff379d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378b866847804da2b63e6421d4d828d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5767eaa0e0a24c198729626de3a06758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GPT-2 Output ---\n",
      "\n",
      "Tutoring session summary:\n",
      "This is a sample sentence for embedding.\n",
      "Please suggest exercises to improve understanding of identifying the coefficients for quadratic equations.\n",
      "\n",
      "Summary and question: What is the relationship between the coefficient of variation and the rate of change in the time series of a given variable? What are the parameters of the model? How do they relate to each other? Is there a correlation between these parameters? Are there any other parameters that can be used to predict the response of an individual variable to changes in time? If so, how can we use them to help us better understand the nature of our models? The answer to these questions is that there are many variables that\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Use an LLM for Generation\n",
    "# --------------------------\n",
    "llm_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "llm_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "llm_model.eval()\n",
    "\n",
    "# Add prompt for the model\n",
    "prompt = (\n",
    "    \"Tutoring session summary:\\n\"\n",
    "    f\"{session_text}\\n\"\n",
    "    \"Please suggest exercises to improve understanding of identifying the coefficients for quadratic equations.\\n\" \n",
    "    \"\\n\"\n",
    "    \"Summary and question:\"\n",
    ")\n",
    "\n",
    "# Encode the prompt and generate\n",
    "inputs = llm_tokenizer(prompt, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "generated = llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\n--- GPT-2 Output ---\\n\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca5933-4055-4858-9761-ce04b9873c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
